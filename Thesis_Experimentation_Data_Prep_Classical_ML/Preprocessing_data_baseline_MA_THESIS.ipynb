{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMcGW988FZVaIUqelG/KNvX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["%pip install datasets --quiet"],"metadata":{"id":"MTa7D6apLK7E","executionInfo":{"status":"ok","timestamp":1723112406285,"user_tz":-120,"elapsed":34908,"user":{"displayName":"Marija Kliocaite","userId":"08439538792170122037"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bd948076-487f-4ce2-ab11-e2871dd90a18"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/547.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m542.7/547.8 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m542.7/547.8 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torch 2.3.1+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.1+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.1+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.1+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.1+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.1+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.1+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.1+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.1+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.1+cu121 requires nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.1+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n","gcsfs 2024.6.1 requires fsspec==2024.6.1, but you have fsspec 2024.5.0 which is incompatible.\n","ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["import sklearn\n","import pandas as pd\n","import numpy as np\n","import random\n","\n","seed = 42\n","\n","np.random.seed(seed)\n","random.seed(seed)"],"metadata":{"id":"OKPJ94b6ApvN","executionInfo":{"status":"ok","timestamp":1723116124001,"user_tz":-120,"elapsed":285,"user":{"displayName":"Marija Kliocaite","userId":"08439538792170122037"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["from datasets import load_dataset\n","sem_eval_2018_task_1 = load_dataset('sem_eval_2018_task_1', 'subtask5.english', trust_remote_code=True)"],"metadata":{"id":"Qlj0cokYFeEY","executionInfo":{"status":"ok","timestamp":1723116081992,"user_tz":-120,"elapsed":2319,"user":{"displayName":"Marija Kliocaite","userId":"08439538792170122037"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["print(sem_eval_2018_task_1['train'][0])\n","print(sem_eval_2018_task_1['validation'][0])\n","print(sem_eval_2018_task_1['test'][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DT-GuYFdGkH2","executionInfo":{"status":"ok","timestamp":1722867506826,"user_tz":-120,"elapsed":493,"user":{"displayName":"Marija Kliocaite","userId":"08439538792170122037"}},"outputId":"70465bb7-7d7f-4546-bc53-75d092788d8b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'ID': '2017-En-21441', 'Tweet': \"“Worry is a down payment on a problem you may never have'. \\xa0Joyce Meyer.  #motivation #leadership #worry\", 'anger': False, 'anticipation': True, 'disgust': False, 'fear': False, 'joy': False, 'love': False, 'optimism': True, 'pessimism': False, 'sadness': False, 'surprise': False, 'trust': True}\n","{'ID': '2018-En-00866', 'Tweet': '@RanaAyyub @rajnathsingh Oh, hidden revenge and anger...I rememberthe time,she rebutted you.', 'anger': True, 'anticipation': False, 'disgust': True, 'fear': False, 'joy': False, 'love': False, 'optimism': False, 'pessimism': False, 'sadness': False, 'surprise': False, 'trust': False}\n","{'ID': '2018-En-01559', 'Tweet': '@Adnan__786__ @AsYouNotWish Dont worry Indian army is on its ways to dispatch all Terrorists to Hell', 'anger': True, 'anticipation': True, 'disgust': False, 'fear': False, 'joy': False, 'love': False, 'optimism': True, 'pessimism': False, 'sadness': False, 'surprise': False, 'trust': True}\n"]}]},{"cell_type":"code","source":["# Example selection for the GPT-4o-mini model\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","def get_single_emotion_tweets(dataset, emotions, min_tokens=5):\n","    \"\"\"\n","    This function takes a multi-label dataset and returns a dictionary with a tweet\n","    for each unique single emotion present in the dataset using cosine similarity,\n","    along with the average similarity scores.\n","\n","    Parameters:\n","    dataset (Dataset): The loaded dataset.\n","    emotions (list): List of possible emotions.\n","    min_tokens (int): Minimum number of tokens a tweet must have to be considered.\n","\n","    Returns:\n","    dict: A dictionary where keys are emotions and values are tuples of (tweet, average similarity score).\n","    \"\"\"\n","    # Initialize dictionary to store tweets for each single emotion\n","    emotion_tweets = {emotion: [] for emotion in emotions}\n","\n","    # Iterate through the dataset\n","    for example in dataset['train']:\n","        tweet = example['Tweet']\n","\n","        # Check if the tweet meets the minimum length requirement\n","        if len(tweet.split()) < min_tokens:\n","            continue\n","\n","        # Create a list of emotions that are labeled as 1 for the current tweet\n","        example_emotions = [emotion for emotion in emotions if example[emotion] == 1]\n","\n","        # Check if the tweet has only one emotion label\n","        if len(example_emotions) == 1:\n","            emotion = example_emotions[0]\n","            emotion_tweets[emotion].append(tweet)\n","\n","    # Remove emotions that do not have any single labeled tweets\n","    emotion_tweets = {k: v for k, v in emotion_tweets.items() if v}\n","\n","    # Vectorize the tweets using TF-IDF\n","    all_tweets = [tweet for tweets in emotion_tweets.values() for tweet in tweets]\n","    vectorizer = TfidfVectorizer(stop_words='english')\n","    tweet_vectors = vectorizer.fit_transform(all_tweets)\n","\n","    # Initialize dictionary to store the best example for each emotion and their average similarity scores\n","    best_examples = {}\n","\n","    # Calculate cosine similarity and select the best example for each emotion\n","    for emotion, tweets in emotion_tweets.items():\n","        if len(tweets) > 1:  # Ensure there are multiple tweets to compare\n","            indices = [all_tweets.index(tweet) for tweet in tweets]\n","            vectors = tweet_vectors[indices]\n","\n","            # Calculate cosine similarity matrix\n","            cosine_sim = cosine_similarity(vectors)\n","\n","            # Average similarity score for each tweet\n","            avg_sim_scores = cosine_sim.mean(axis=1)\n","\n","            # Get the index of the tweet with the highest average similarity\n","            best_idx = np.argmax(avg_sim_scores)\n","            best_tweet = tweets[best_idx]\n","            best_score = avg_sim_scores[best_idx]\n","\n","            best_examples[emotion] = (best_tweet, best_score)\n","        else:\n","            # If there's only one tweet for this emotion, take that as the best example with a similarity score of 1\n","            best_examples[emotion] = (tweets[0], 1.0)\n","\n","    return best_examples\n","\n","# Define the list of emotions\n","emotions = ['anger', 'anticipation', 'disgust', 'fear', 'joy', 'love', 'optimism', 'pessimism', 'sadness', 'surprise', 'trust']\n","\n","# Get the best examples for each emotion\n","best_examples = get_single_emotion_tweets(sem_eval_2018_task_1, emotions, min_tokens=5)\n","\n","# Output the best examples with their cosine similarity scores\n","for emotion, (tweet, score) in best_examples.items():\n","    print(f\"Best example for {emotion}: {tweet} (Average Cosine Similarity: {score:.4f})\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nnn_6x956HRd","executionInfo":{"status":"ok","timestamp":1722867969179,"user_tz":-120,"elapsed":1709,"user":{"displayName":"Marija Kliocaite","userId":"08439538792170122037"}},"outputId":"cc117a31-a167-493b-e9e3-d2a79a30688c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best example for anger: I need some to help with my anger (Average Cosine Similarity: 0.0294)\n","Best example for anticipation: Let's get drunk and tell each other things we're afraid to say when we're sober. (Average Cosine Similarity: 0.0290)\n","Best example for disgust: I don't like pineapple I only eat them on pizza, they lose the sting when they get cooked. (Average Cosine Similarity: 0.0327)\n","Best example for fear: I'm so over having anxiety (Average Cosine Similarity: 0.0381)\n","Best example for joy: Watch this amazing live.ly broadcast by @izzybuzy365 #lively #musically (Average Cosine Similarity: 0.0466)\n","Best example for love: @lizbon @anomalily @gerikkransky Sorry for the levity if at all inappropriate but this combined with my love of Charlotte reminds me rn... (Average Cosine Similarity: 0.3496)\n","Best example for optimism: The point of living, and being an optimist, is to be foolish enough to believe the best is yet to come' - Peter Ustinov #optimism #quote (Average Cosine Similarity: 0.0376)\n","Best example for pessimism: Actually I always idealize the end of my relationships .. Such a pessimist (Average Cosine Similarity: 0.0900)\n","Best example for sadness: What day is it #lost (Average Cosine Similarity: 0.0328)\n","Best example for surprise: @SimplyMayaMarie @STILLStanding_B 😂😂😂 y'all know I'm crazy its just shocking that's all (Average Cosine Similarity: 0.0960)\n"]}]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity\n","from datasets import load_dataset\n","\n","# Load the dataset\n","sem_eval_2018_task_1 = load_dataset('sem_eval_2018_task_1', 'subtask5.english', trust_remote_code=True)\n","\n","def get_best_emotion_tweet(dataset, emotion):\n","    \"\"\"\n","    This function takes a multi-label dataset and returns the best tweet for a specific emotion\n","    using cosine similarity, along with the average similarity score.\n","\n","    Parameters:\n","    dataset (Dataset): The loaded dataset.\n","    emotion (str): The emotion to find the best tweet for.\n","\n","    Returns:\n","    tuple: A tuple containing the best tweet and its average similarity score.\n","    \"\"\"\n","    # Initialize list to store tweets for the specified emotion\n","    emotion_tweets = []\n","\n","    # Iterate through the dataset\n","    for example in dataset['train']:\n","        tweet = example['Tweet']\n","\n","        # Add tweet to the list if it is labeled with the specified emotion\n","        if example[emotion] == 1:\n","            emotion_tweets.append(tweet)\n","\n","    if not emotion_tweets:\n","        return None, None\n","\n","    # Vectorize the tweets using TF-IDF\n","    vectorizer = TfidfVectorizer(stop_words='english')\n","    tweet_vectors = vectorizer.fit_transform(emotion_tweets)\n","\n","    # Calculate cosine similarity matrix\n","    cosine_sim = cosine_similarity(tweet_vectors)\n","\n","    # Average similarity score for each tweet\n","    avg_sim_scores = cosine_sim.mean(axis=1)\n","\n","    # Get the index of the tweet with the highest average similarity\n","    best_idx = np.argmax(avg_sim_scores)\n","    best_tweet = emotion_tweets[best_idx]\n","    best_score = avg_sim_scores[best_idx]\n","\n","    return best_tweet, best_score\n","\n","# Specify the emotion\n","emotion = 'trust'\n","\n","# Get the best example for the specified emotion\n","best_tweet, best_score = get_best_emotion_tweet(sem_eval_2018_task_1, emotion)\n","\n","# Output the best example with its cosine similarity score\n","if best_tweet:\n","    print(f\"Best example for {emotion}: {best_tweet} (Average Cosine Similarity: {best_score:.4f})\")\n","else:\n","    print(f\"No tweets found for emotion: {emotion}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9G2zQXGT9Eqp","executionInfo":{"status":"ok","timestamp":1722869107385,"user_tz":-120,"elapsed":5514,"user":{"displayName":"Marija Kliocaite","userId":"08439538792170122037"}},"outputId":"ab5273ef-890d-4683-c030-0bfcdb1eb08b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Best example for trust: @ThatBritishDude no okay you don't not need to be going out of your way to make sure you are pleasing everyone do what makes you happy (Average Cosine Similarity: 0.0216)\n"]}]},{"cell_type":"code","source":["# Average length of a tweet, longest tweet, shortest tweet (based on the number of tokens)\n","\n","def analyze_tweet_tokens(dataset):\n","    \"\"\"\n","    This function takes a dataset and returns the average number of tokens per tweet,\n","    the longest tweet based on token count, and the shortest tweet based on token count.\n","\n","    Parameters:\n","    dataset (Dataset): The loaded dataset.\n","\n","    Returns:\n","    dict: A dictionary with the average number of tokens, longest tweet, and shortest tweet.\n","    \"\"\"\n","    # Initialize variables to store the longest and shortest tweets\n","    longest_tweet = \"\"\n","    shortest_tweet = None\n","    longest_tokens = 0\n","    shortest_tokens = float('inf')\n","    total_tokens = 0\n","    tweet_count = 0\n","\n","    # Simple tokenization function\n","    def simple_tokenize(text):\n","        return text.split()\n","\n","    # Iterate through the dataset to find tweet token counts\n","    for example in dataset['train']:\n","        tweet = example['Tweet']\n","        tokens = simple_tokenize(tweet)\n","        num_tokens = len(tokens)\n","\n","        # Update total tokens and count for average calculation\n","        total_tokens += num_tokens\n","        tweet_count += 1\n","\n","        # Check for longest tweet based on token count\n","        if num_tokens > longest_tokens:\n","            longest_tokens = num_tokens\n","            longest_tweet = tweet\n","\n","        # Check for shortest tweet based on token count\n","        if num_tokens < shortest_tokens:\n","            shortest_tokens = num_tokens\n","            shortest_tweet = tweet\n","\n","    # Calculate average number of tokens\n","    average_tokens = total_tokens / tweet_count if tweet_count > 0 else 0\n","\n","    return {\n","        \"average_tokens\": average_tokens,\n","        \"longest_tweet\": longest_tweet,\n","        \"longest_tweet_tokens\": longest_tokens,\n","        \"shortest_tweet\": shortest_tweet,\n","        \"shortest_tweet_tokens\": shortest_tokens\n","    }\n","\n","# Analyze tweet tokens\n","tweet_token_analysis = analyze_tweet_tokens(sem_eval_2018_task_1)\n","\n","# Print the results\n","print(f\"Average number of tokens per tweet: {tweet_token_analysis['average_tokens']:.2f}\")\n","print(f\"Longest tweet: {tweet_token_analysis['longest_tweet']} ({tweet_token_analysis['longest_tweet_tokens']} tokens)\")\n","print(f\"Shortest tweet: {tweet_token_analysis['shortest_tweet']} ({tweet_token_analysis['shortest_tweet_tokens']} tokens)\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SBFIUZkutH6y","executionInfo":{"status":"ok","timestamp":1722260860125,"user_tz":-120,"elapsed":2860,"user":{"displayName":"Marija Kliocaite","userId":"08439538792170122037"}},"outputId":"998f35f0-efbf-4457-c19c-3eab74e329ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average number of tokens per tweet: 16.06\n","Longest tweet: I feel like a burden every day that I waste but I don't know how to get out of this bc I get so discouraged all I wanna do is lay around 🙃 (33 tokens)\n","Shortest tweet: testing  (1 tokens)\n"]}]},{"cell_type":"code","source":["# Function to count emotions in a dataset split\n","def count_emotions(dataset_split):\n","    emotion_counts = {}\n","\n","    # Iterate through examples in the dataset split\n","    for example in dataset_split:\n","        # Iterate through emotions in the example\n","        for emotion, value in example.items():\n","            # Check if the value is True (indicating the presence of the emotion)\n","            if value:\n","                # Increment the count for the emotion\n","                emotion_counts[emotion] = emotion_counts.get(emotion, 0) + 1\n","\n","    return emotion_counts\n","\n","# Count emotions in the train split\n","train_emotion_counts = count_emotions(sem_eval_2018_task_1['train'])\n","print(\"Train Split Emotion Counts:\")\n","print(train_emotion_counts)\n","\n","# Count emotions in the validation split\n","val_emotion_counts = count_emotions(sem_eval_2018_task_1['validation'])\n","print(\"\\nValidation Split Emotion Counts:\")\n","print(val_emotion_counts)\n","\n","# Count emotions in the test split\n","test_emotion_counts = count_emotions(sem_eval_2018_task_1['test'])\n","print(\"\\nTest Split Emotion Counts:\")\n","print(test_emotion_counts)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LcXXa80EHVCa","executionInfo":{"status":"ok","timestamp":1719857618873,"user_tz":-120,"elapsed":1327,"user":{"displayName":"Marija Kliocaite","userId":"08439538792170122037"}},"outputId":"10b29f7c-a64f-4a94-94db-f6ee161b6f94"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train Split Emotion Counts:\n","{'ID': 6838, 'Tweet': 6838, 'anticipation': 978, 'optimism': 1984, 'trust': 357, 'joy': 2477, 'love': 700, 'anger': 2544, 'disgust': 2602, 'pessimism': 795, 'sadness': 2008, 'fear': 1242, 'surprise': 361}\n","\n","Validation Split Emotion Counts:\n","{'ID': 886, 'Tweet': 886, 'anger': 315, 'disgust': 319, 'joy': 400, 'love': 132, 'optimism': 307, 'fear': 121, 'pessimism': 100, 'sadness': 265, 'surprise': 35, 'anticipation': 124, 'trust': 43}\n","\n","Test Split Emotion Counts:\n","{'ID': 3259, 'Tweet': 3259, 'anger': 1101, 'anticipation': 425, 'optimism': 1143, 'trust': 153, 'disgust': 1099, 'sadness': 960, 'joy': 1442, 'fear': 485, 'pessimism': 375, 'love': 516, 'surprise': 170}\n"]}]},{"cell_type":"code","source":["# Function to count occurrences of multiple emotions in a dataset split\n","def count_multiple_emotions(dataset_split):\n","    multiple_emotion_count = 0\n","\n","    # Iterate through examples in the dataset split\n","    for example in dataset_split:\n","        # Count the number of True values in the example\n","        num_true_values = sum(1 for value in example.values() if value == True)\n","\n","        # If there are more than 1 True values, increment the count\n","        if num_true_values > 1:\n","            multiple_emotion_count += 1\n","\n","    return multiple_emotion_count\n","\n","# Count occurrences of multiple emotions in the train split\n","train_multiple_emotion_count = count_multiple_emotions(sem_eval_2018_task_1['train'])\n","print(\"Number of cases with multiple emotions in train split:\", train_multiple_emotion_count)\n","\n","# Count occurrences of multiple emotions in the validation split\n","val_multiple_emotion_count = count_multiple_emotions(sem_eval_2018_task_1['validation'])\n","print(\"Number of cases with multiple emotions in validation split:\", val_multiple_emotion_count)\n","\n","# Count occurrences of multiple emotions in the test split\n","test_multiple_emotion_count = count_multiple_emotions(sem_eval_2018_task_1['test'])\n","print(\"Number of cases with multiple emotions in test split:\", test_multiple_emotion_count)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yf1j5T6xJS1L","executionInfo":{"status":"ok","timestamp":1719849564801,"user_tz":-120,"elapsed":7973,"user":{"displayName":"Marija Kliocaite","userId":"08439538792170122037"}},"outputId":"c11e71f8-1578-4572-eb22-198001d4635f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of cases with multiple emotions in train split: 5652\n","Number of cases with multiple emotions in validation split: 755\n","Number of cases with multiple emotions in test split: 2802\n"]}]},{"cell_type":"code","source":["# Function to find the maximum number of emotions in a single example in a dataset split\n","def max_emotions_in_example(dataset_split):\n","    max_emotion_count = 0\n","    max_emotion_example = None\n","\n","    # Iterate through examples in the dataset split\n","    for example in dataset_split:\n","        # Count the number of True values in the example\n","        num_true_values = sum(1 for value in example.values() if value == True)\n","\n","        # Update max_emotion_count if num_true_values is greater\n","        if num_true_values > max_emotion_count:\n","            max_emotion_count = num_true_values\n","            max_emotion_example = example\n","\n","    return max_emotion_count, max_emotion_example\n","\n","# Find the maximum number of emotions in a single example for the train split\n","train_max_emotion_count, train_max_emotion_example = max_emotions_in_example(sem_eval_2018_task_1['train'])\n","print(\"Maximum number of emotions in a single example in the train split:\", train_max_emotion_count)\n","print(\"Example with maximum number of emotions in train split:\")\n","print(train_max_emotion_example)\n","\n","# Find the maximum number of emotions in a single example for the validation split\n","val_max_emotion_count, val_max_emotion_example = max_emotions_in_example(sem_eval_2018_task_1['validation'])\n","print(\"\\nMaximum number of emotions in a single example in the validation split:\", val_max_emotion_count)\n","print(\"Example with maximum number of emotions in validation split:\")\n","print(val_max_emotion_example)\n","\n","# Find the maximum number of emotions in a single example for the test split\n","test_max_emotion_count, test_max_emotion_example = max_emotions_in_example(sem_eval_2018_task_1['test'])\n","print(\"\\nMaximum number of emotions in a single example in the test split:\", test_max_emotion_count)\n","print(\"Example with maximum number of emotions in test split:\")\n","print(test_max_emotion_example)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tzz1SYJpLN4g","executionInfo":{"status":"ok","timestamp":1719849569192,"user_tz":-120,"elapsed":4401,"user":{"displayName":"Marija Kliocaite","userId":"08439538792170122037"}},"outputId":"5260916f-b982-4717-bea1-a67b5c4ede7d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Maximum number of emotions in a single example in the train split: 6\n","Example with maximum number of emotions in train split:\n","{'ID': '2017-En-22055', 'Tweet': \"I had really strange and awful dreams last night. I'd didn't even eat cheese before bed  #lovemysleep\", 'anger': True, 'anticipation': False, 'disgust': True, 'fear': True, 'joy': True, 'love': True, 'optimism': False, 'pessimism': False, 'sadness': True, 'surprise': False, 'trust': False}\n","\n","Maximum number of emotions in a single example in the validation split: 6\n","Example with maximum number of emotions in validation split:\n","{'ID': '2018-En-01944', 'Tweet': '@_elliegillxx @0liviarobertson Poor Lyn 😂😂😂 livv I hope she forgets yours this year in revenge', 'anger': True, 'anticipation': False, 'disgust': True, 'fear': False, 'joy': True, 'love': False, 'optimism': True, 'pessimism': True, 'sadness': True, 'surprise': False, 'trust': False}\n","\n","Maximum number of emotions in a single example in the test split: 6\n","Example with maximum number of emotions in test split:\n","{'ID': '2018-En-01560', 'Tweet': '@Sceptic_1985 I think we underestimate them at our peril. IMHO Bannon, Ryan, McConnell, ect. will accomplish terrible things if allowed to.', 'anger': False, 'anticipation': True, 'disgust': True, 'fear': True, 'joy': False, 'love': False, 'optimism': True, 'pessimism': True, 'sadness': True, 'surprise': False, 'trust': False}\n"]}]},{"cell_type":"markdown","source":["Preparing data for training and evaluation.\n","The TRAIN and VALIDATION data is combined and transformed with TfidfVectorizer + Scaler."],"metadata":{"id":"0INSc6CmQIB7"}},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.preprocessing import MaxAbsScaler\n","\n","# Converting the DatasetDict into a DataFrame\n","df_train = pd.DataFrame(sem_eval_2018_task_1['train'])\n","df_validation = pd.DataFrame(sem_eval_2018_task_1['validation'])\n","df = pd.concat([df_train, df_validation])\n","\n","# Extract texts and labels for the train set\n","texts_train = df['Tweet']\n","labels_train = df.drop(columns=['Tweet', 'ID'])\n","\n","# Extract texts and labels for the test set\n","df_test = pd.DataFrame(sem_eval_2018_task_1['test'])\n","texts_test = df_test['Tweet']\n","labels_test = df_test.drop(columns=['Tweet', 'ID'])\n","\n","# Transform the text data to TF-IDF features\n","vectorizer = TfidfVectorizer(max_features=5000)\n","X_train = vectorizer.fit_transform(texts_train)\n","X_test = vectorizer.transform(texts_test)\n","\n","# Apply Standard Scaling\n","scaler = MaxAbsScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)"],"metadata":{"id":"qly3cISvPybZ","executionInfo":{"status":"ok","timestamp":1723112451276,"user_tz":-120,"elapsed":4122,"user":{"displayName":"Marija Kliocaite","userId":"08439538792170122037"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["OneVsRestClassifier + SVC\n","Seed"],"metadata":{"id":"rd61daZGd6fe"}},{"cell_type":"code","source":["from sklearn.multiclass import OneVsRestClassifier\n","from sklearn.svm import SVC\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import f1_score, accuracy_score, multilabel_confusion_matrix\n","\n","# Define model and parameter grid\n","model = OneVsRestClassifier(SVC(random_state=42))\n","parameters = [\n","    {\n","        \"estimator__C\": [1, 2, 4],\n","        \"estimator__kernel\": [\"poly\", \"rbf\"],\n","        \"estimator__degree\": [1, 2],\n","    },\n","]\n","\n","# Perform grid search with cross-validation\n","clf = GridSearchCV(model, parameters, scoring='accuracy', n_jobs=-1)\n","clf.fit(X_train, labels_train)\n","\n","# Print best parameters and best score from grid search\n","print(clf.best_params_, clf.best_score_)\n","\n","# Predict on test data using the best estimator\n","best_model = clf.best_estimator_\n","labels_pred = best_model.predict(X_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xZfmrrIGdrbO","executionInfo":{"status":"ok","timestamp":1722783775965,"user_tz":-120,"elapsed":3499406,"user":{"displayName":"Marija Kliocaite","userId":"08439538792170122037"}},"outputId":"9b7d2aca-f786-43bb-e637-22ca94553ceb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'estimator__C': 1, 'estimator__degree': 1, 'estimator__kernel': 'poly'} 0.18202701343125913\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import f1_score, accuracy_score, multilabel_confusion_matrix\n","\n","# Calculate test accuracy and F1 scores\n","accuracy_test = accuracy_score(labels_test, labels_pred) * 100\n","f1_macro_test = f1_score(labels_test, labels_pred, average='macro') * 100\n","f1_micro_test = f1_score(labels_test, labels_pred, average='micro') * 100\n","\n","# Calculate confusion matrix\n","confusion_matrix_test = multilabel_confusion_matrix(labels_test, labels_pred)\n","\n","# Print the results\n","print(f\"Test Accuracy: {accuracy_test:.2f}\")\n","print(f\"Test F1-macro: {f1_macro_test:.2f}\")\n","print(f\"Test F1-micro: {f1_micro_test:.2f}\")\n","print(\"Confusion Matrix:\")\n","label_columns = ['anticipation', 'optimism', 'trust', 'joy', 'love', 'anger', 'disgust', 'pessimism', 'sadness', 'fear', 'surprise']\n","for label, matrix in zip(label_columns, confusion_matrix_test):\n","    print(f\"Label: {label}\")\n","    print(matrix)\n","    print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I7NV1kyYsE3p","executionInfo":{"status":"ok","timestamp":1722783775966,"user_tz":-120,"elapsed":12,"user":{"displayName":"Marija Kliocaite","userId":"08439538792170122037"}},"outputId":"98e82e14-2699-4c0f-d770-0c1bbe6812bd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Accuracy: 18.04\n","Test F1-macro: 37.94\n","Test F1-micro: 55.20\n","Confusion Matrix:\n","Label: anticipation\n","[[1928  230]\n"," [ 466  635]]\n","\n","Label: optimism\n","[[2827    7]\n"," [ 420    5]]\n","\n","Label: trust\n","[[1853  307]\n"," [ 525  574]]\n","\n","Label: joy\n","[[2740   34]\n"," [ 266  219]]\n","\n","Label: love\n","[[1638  179]\n"," [ 490  952]]\n","\n","Label: anger\n","[[2702   41]\n"," [ 376  140]]\n","\n","Label: disgust\n","[[1884  232]\n"," [ 611  532]]\n","\n","Label: pessimism\n","[[2881    3]\n"," [ 366    9]]\n","\n","Label: sadness\n","[[2205   94]\n"," [ 603  357]]\n","\n","Label: fear\n","[[3088    1]\n"," [ 163    7]]\n","\n","Label: surprise\n","[[3106    0]\n"," [ 153    0]]\n","\n"]}]}]}
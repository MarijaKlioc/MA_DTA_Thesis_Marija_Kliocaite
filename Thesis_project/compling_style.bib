@String{ACL01 = "Proceedings of the 39th Annual Conference of the Association for Computational Linguistics (ACL-01)"}

@article{article,
author = {Digman, John},
year = {2003},
month = {11},
pages = {417-440},
title = {Personality Structure: Emergence of the Five-Factor Model},
volume = {41},
journal = {Annual Review of Psychology},
doi = {10.1146/annurev.ps.41.020190.002221}
}

@article{structure_of_phenotypic_personality_traits,
author = {Goldberg, Lewis},
year = {1993},
month = {01},
pages = {26-34},
title = {The Structure of Phenotypic Personality Traits},
volume = {48},
journal = {American Psychologist},
doi = {10.1037/0003-066X.48.1.26}
}

@article{validation_of_the_five_factor_model,
author = {McCrae, Robert and Costa, Paul},
year = {1987},
month = {01},
pages = {81-90},
title = {Validation of the Five-Factor Model of Personality Across Instruments and Observers},
volume = {52},
journal = {Journal of personality and social psychology},
doi = {10.1037/0022-3514.52.1.81}
}

@misc{hilliard2024elicitingpersonalitytraitslarge,
      title={Eliciting Personality Traits in Large Language Models}, 
      author={Airlie Hilliard and Cristian Munoz and Zekun Wu and Adriano Soares Koshiyama},
      year={2024},
      eprint={2402.08341},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.08341}, 
}

@InProceedings{TiedemannThottingal:EAMT2020,
  author = {J{\"o}rg Tiedemann and Santhosh Thottingal},
  title = {{OPUS-MT} — {B}uilding open translation services for the {W}orld},
  booktitle = {Proceedings of the 22nd Annual Conferenec of the European Association for Machine Translation (EAMT)},
  year = {2020},
  address = {Lisbon, Portugal}
 }

@inproceedings{demszky-etal-2020-goemotions,
    title = "{G}o{E}motions: A Dataset of Fine-Grained Emotions",
    author = "Demszky, Dorottya  and
      Movshovitz-Attias, Dana  and
      Ko, Jeongwoo  and
      Cowen, Alan  and
      Nemade, Gaurav  and
      Ravi, Sujith",
    editor = "Jurafsky, Dan  and
      Chai, Joyce  and
      Schluter, Natalie  and
      Tetreault, Joel",
    booktitle = "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics",
    month = jul,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2020.acl-main.372",
    doi = "10.18653/v1/2020.acl-main.372",
    pages = "4040--4054",
    abstract = "Understanding emotion expressed in language has a wide range of applications, from building empathetic chatbots to detecting harmful online behavior. Advancement in this area can be improved using large-scale datasets with a fine-grained typology, adaptable to multiple downstream tasks. We introduce GoEmotions, the largest manually annotated dataset of 58k English Reddit comments, labeled for 27 emotion categories or Neutral. We demonstrate the high quality of the annotations via Principal Preserved Component Analysis. We conduct transfer learning experiments with existing emotion benchmarks to show that our dataset generalizes well to other domains and different emotion taxonomies. Our BERT-based model achieves an average F1-score of .46 across our proposed taxonomy, leaving much room for improvement.",
}

@inproceedings{mohammad-kiritchenko-2018-understanding,
    title = "Understanding Emotions: A Dataset of Tweets to Study Interactions between Affect Categories",
    author = "Mohammad, Saif  and
      Kiritchenko, Svetlana",
    editor = "Calzolari, Nicoletta  and
      Choukri, Khalid  and
      Cieri, Christopher  and
      Declerck, Thierry  and
      Goggi, Sara  and
      Hasida, Koiti  and
      Isahara, Hitoshi  and
      Maegaard, Bente  and
      Mariani, Joseph  and
      Mazo, H{\'e}l{\`e}ne  and
      Moreno, Asuncion  and
      Odijk, Jan  and
      Piperidis, Stelios  and
      Tokunaga, Takenobu",
    booktitle = "Proceedings of the Eleventh International Conference on Language Resources and Evaluation ({LREC} 2018)",
    month = may,
    year = "2018",
    address = "Miyazaki, Japan",
    publisher = "European Language Resources Association (ELRA)",
    url = "https://aclanthology.org/L18-1030",
}

@inproceedings{94205144dd7945cc99b5a6544451b668,
title = "From humans to machines: can ChatGPT-like LLMs effectively replace human annotators in NLP tasks",
author = "Surendrabikram Thapa and Usman Naseem and Mehwish Nasim",
year = "2023",
month = jun,
doi = "10.36190/2023.15",
language = "English",
booktitle = "Workshop Proceedings of the 17th International AAAI Conference on Web and Social Media",
publisher = "Association for the Advancement of Artificial Intelligence (AAAI)",
note = "17th International AAAI Conference on Web and Social Media, ICWSM 2023 ; Conference date: 05-06-2023 Through 08-06-2023",
}

Powered

@article{10.1016/j.eswa.2022.118534,
author = {Ameer, Iqra and B\"{o}l\"{u}c\"{u}, Necva and Siddiqui, Muhammad Hammad Fahim and Can, Burcu and Sidorov, Grigori and Gelbukh, Alexander},
title = {Multi-label emotion classification in texts using transfer learning},
year = {2023},
issue_date = {Mar 2023},
publisher = {Pergamon Press, Inc.},
address = {USA},
volume = {213},
number = {PA},
issn = {0957-4174},
url = {https://doi.org/10.1016/j.eswa.2022.118534},
doi = {10.1016/j.eswa.2022.118534},
journal = {Expert Syst. Appl.},
month = {mar},
numpages = {13},
keywords = {Social media, Attention mechanism, Transformer Networks, Bi-LSTM, Multi-label emotion classification}
}

@article{DBLP:journals/corr/abs-2003-02245,
  author = {Varun Kumar and Ashutosh Choudhary and Eunah Cho},
  title = {Data Augmentation using Pre-trained Transformer Models},
  journal      = {CoRR},
  volume       = {abs/2003.02245},
  year         = {2020},
  url          = {https://arxiv.org/abs/2003.02245},
  eprinttype    = {arXiv},
  eprint       = {2003.02245},
  timestamp    = {Tue, 10 Mar 2020 13:33:48 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2003-02245.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{baziotis2018ntuaslp,
      title={NTUA-SLP at SemEval-2018 Task 1: Predicting Affective Content in Tweets with Deep Attentive RNNs and Transfer Learning}, 
      author={Christos Baziotis and Nikos Athanasiou and Alexandra Chronopoulou and Athanasia Kolovou and Georgios Paraskevopoulos and Nikolaos Ellinas and Shrikanth Narayanan and Alexandros Potamianos},
      year={2018},
      eprint={1804.06658},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{ouyang2022traininglanguagemodelsfollow,
      title={Training language models to follow instructions with human feedback}, 
      author={Long Ouyang and Jeff Wu and Xu Jiang and Diogo Almeida and Carroll L. Wainwright and Pamela Mishkin and Chong Zhang and Sandhini Agarwal and Katarina Slama and Alex Ray and John Schulman and Jacob Hilton and Fraser Kelton and Luke Miller and Maddie Simens and Amanda Askell and Peter Welinder and Paul Christiano and Jan Leike and Ryan Lowe},
      year={2022},
      eprint={2203.02155},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2203.02155}, 
}

@inproceedings{Radford2019LanguageMA,
  title={Language Models are Unsupervised Multitask Learners},
  author={Alec Radford and Jeff Wu and Rewon Child and David Luan and Dario Amodei and Ilya Sutskever},
  year={2019},
  url={https://api.semanticscholar.org/CorpusID:160025533}
}

@misc{rutinowski2023selfperception,
      title={The Self-Perception and Political Biases of ChatGPT}, 
      author={Jérôme Rutinowski and Sven Franke and Jan Endendyk and Ina Dormuth and Markus Pauly},
      year={2023},
      eprint={2304.07333},
      archivePrefix={arXiv},
      primaryClass={cs.CY}
}

@misc{møller2023prompt,
      title={Is a prompt and a few samples all you need? Using GPT-4 for data augmentation in low-resource classification tasks}, 
      author={Anders Giovanni Møller and Jacob Aarup Dalsgaard and Arianna Pera and Luca Maria Aiello},
      year={2023},
      eprint={2304.13861},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{xie2020unsuperviseddataaugmentationconsistency,
      title={Unsupervised Data Augmentation for Consistency Training}, 
      author={Qizhe Xie and Zihang Dai and Eduard Hovy and Minh-Thang Luong and Quoc V. Le},
      year={2020},
      eprint={1904.12848},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1904.12848}, 
}

@misc{wei2019eda,
      title={EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks}, 
      author={Jason Wei and Kai Zou},
      year={2019},
      eprint={1901.11196},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{10.1145/3357384.3358040,
author = {Rizos, Georgios and Hemker, Konstantin and Schuller, Bj\"{o}rn},
title = {Augment to Prevent: Short-Text Data Augmentation in Deep Learning for Hate-Speech Classification},
year = {2019},
isbn = {9781450369763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3357384.3358040},
doi = {10.1145/3357384.3358040},
abstract = {In this paper, we address the issue of augmenting text data in supervised Natural Language Processing problems, exemplified by deep online hate speech classification. A great challenge in this domain is that although the presence of hate speech can be deleterious to the quality of service provided by social platforms, it still comprises only a tiny fraction of the content that can be found online, which can lead to performance deterioration due to majority class overfitting. To this end, we perform a thorough study on the application of deep learning to the hate speech detection problem: a) we propose three text-based data augmentation techniques aimed at reducing the degree of class imbalance and to maximise the amount of information we can extract from our limited resources and b) we apply them on a selection of top-performing deep architectures and hate speech databases in order to showcase their generalisation properties. The data augmentation techniques are based on a) synonym replacement based on word embedding vector closeness, b) warping of the word tokens along the padded sequence or c) class-conditional, recurrent neural language generation. Our proposed framework yields a significant increase in multi-class hate speech detection, outperforming the baseline in the largest online hate speech database by an absolute 5.7\% increase in Macro-F1 score and 30\% in hate speech class recall.},
booktitle = {Proceedings of the 28th ACM International Conference on Information and Knowledge Management},
pages = {991–1000},
numpages = {10},
keywords = {class imbalance, online hate speech detection, short text data augmentation},
location = {Beijing, China},
series = {CIKM '19}
}

@misc{li2023synthetic,
      title={Synthetic Data Generation with Large Language Models for Text Classification: Potential and Limitations}, 
      author={Zhuoyan Li and Hangxiao Zhu and Zhuoran Lu and Ming Yin},
      year={2023},
      eprint={2310.07849},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{zhang2020data,
      title={On Data Augmentation for Extreme Multi-label Classification}, 
      author={Danqing Zhang and Tao Li and Haiyang Zhang and Bing Yin},
      year={2020},
      eprint={2009.10778},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{van-nooten-daelemans-2023-improving,
    title = "Improving {D}utch Vaccine Hesitancy Monitoring via Multi-Label Data Augmentation with {GPT}-3.5",
    author = "Van Nooten, Jens  and
      Daelemans, Walter",
    editor = "Barnes, Jeremy  and
      De Clercq, Orph{\'e}e  and
      Klinger, Roman",
    booktitle = "Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, {\&} Social Media Analysis",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.wassa-1.23",
    doi = "10.18653/v1/2023.wassa-1.23",
    pages = "251--270",
    abstract = "In this paper, we leverage the GPT-3.5 language model both using the Chat-GPT API interface and the GPT-3.5 API interface to generate realistic examples of anti-vaccination tweets in Dutch with the aim of augmenting an imbalanced multi-label vaccine hesitancy argumentation classification dataset. In line with previous research, we devise a prompt that, on the one hand, instructs the model to generate realistic examples based on the gold standard dataset and, on the other hand, to assign multiple pseudo-labels (or a single pseudo-label) to the generated instances. We then augment our gold standard data with the generated examples and evaluate the impact thereof in a cross-validation setting with several state-of-the-art Dutch large language models. This augmentation technique predominantly shows improvements in F1 for classifying underrepresented classes while increasing the overall recall, paired with a slight decrease in precision for more common classes. Furthermore, we examine how well the synthetic data generalises to human data in the classification task. To our knowledge, we are the first to utilise Chat-GPT and GPT-3.5 for augmenting a Dutch multi-label dataset classification task.",
}

@misc{brown2020languagemodelsfewshotlearners,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2005.14165}, 
}

@incollection{ZHANG1992470,
title = {Selecting Typical Instances in Instance-Based Learning},
editor = {Derek Sleeman and Peter Edwards},
booktitle = {Machine Learning Proceedings 1992},
publisher = {Morgan Kaufmann},
address = {San Francisco (CA)},
pages = {470-479},
year = {1992},
isbn = {978-1-55860-247-2},
doi = {https://doi.org/10.1016/B978-1-55860-247-2.50066-8},
url = {https://www.sciencedirect.com/science/article/pii/B9781558602472500668},
author = {Jianping Zhang},
abstract = {Concepts involved in real world applications usually possess graded structures. Instead of being equivalent, instances of a concept may be characterized by a degree of typicality in representing the concept. Typical instances of a concept usually better characterize the concept than atypical instances do. This paper presents an instance-based learning approach in which typical instances are selected to store as concept descriptions. It first addresses the issue of measuring the typicality of an instance with respect to its concept. Then, it empirically shows that some concepts in standard datasets do have graded structures. Finally, it presents a simple instance-based learning and classification algorithm that successfully uses typicalities of instances. This approach has been tested on both artificial and practical domains, and compared with three different IBL approaches. The experimental results showed that the approach recorded lower storage requirements and higher classification accuracies than previous instance-based algorithms on several domains.}
}

@InProceedings{10.1007/978-3-642-23808-6_10,
author="Sechidis, Konstantinos
and Tsoumakas, Grigorios
and Vlahavas, Ioannis",
editor="Gunopulos, Dimitrios
and Hofmann, Thomas
and Malerba, Donato
and Vazirgiannis, Michalis",
title="On the Stratification of Multi-label Data",
booktitle="Machine Learning and Knowledge Discovery in Databases",
year="2011",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="145--158",
abstract="Stratified sampling is a sampling method that takes into account the existence of disjoint groups within a population and produces samples where the proportion of these groups is maintained. In single-label classification tasks, groups are differentiated based on the value of the target variable. In multi-label learning tasks, however, where there are multiple target variables, it is not clear how stratified sampling could/should be performed. This paper investigates stratification in the multi-label data context. It considers two stratification methods for multi-label data and empirically compares them along with random sampling on a number of datasets and based on a number of evaluation criteria. The results reveal some interesting conclusions with respect to the utility of each method for particular types of multi-label datasets.",
isbn="978-3-642-23808-6"
}

@article{DBLP:journals/corr/abs-1810-04805,
  author       = {Jacob Devlin and
                  Ming{-}Wei Chang and
                  Kenton Lee and
                  Kristina Toutanova},
  title        = {{BERT:} Pre-training of Deep Bidirectional Transformers for Language
                  Understanding},
  journal      = {CoRR},
  volume       = {abs/1810.04805},
  year         = {2018},
  url          = {http://arxiv.org/abs/1810.04805},
  eprinttype    = {arXiv},
  eprint       = {1810.04805},
  timestamp    = {Tue, 30 Oct 2018 20:39:56 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1810-04805.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@misc{benbaruch2021asymmetriclossmultilabelclassification,
      title={Asymmetric Loss For Multi-Label Classification}, 
      author={Emanuel Ben-Baruch and Tal Ridnik and Nadav Zamir and Asaf Noy and Itamar Friedman and Matan Protter and Lihi Zelnik-Manor},
      year={2021},
      eprint={2009.14119},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2009.14119}, 
}

@inproceedings{li-etal-2023-enhancing-extreme,
    title = "Enhancing Extreme Multi-Label Text Classification: Addressing Challenges in Model, Data, and Evaluation",
    author = "Li, Dan  and
      Zhu, Zi Long  and
      van de Loo, Janneke  and
      Masip Gomez, Agnes  and
      Yadav, Vikrant  and
      Tsatsaronis, Georgios  and
      Afzal, Zubair",
    editor = "Wang, Mingxuan  and
      Zitouni, Imed",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-industry.30",
    doi = "10.18653/v1/2023.emnlp-industry.30",
    pages = "313--321",
    abstract = "Extreme multi-label text classification is a prevalent task in industry, but it frequently encounters challenges in terms of machine learning perspectives, including model limitations, data scarcity, and time-consuming evaluation. This paper aims to mitigate these issues by introducing novel approaches. Firstly, we propose a label ranking model as an alternative to the conventional SciBERT-based classification model, enabling efficient handling of large-scale labels and accommodating new labels. Secondly, we present an active learning-based pipeline that addresses the data scarcity of new labels during the update of a classification system. Finally, we introduce ChatGPT to assist with model evaluation. Our experiments demonstrate the effectiveness of these techniques in enhancing the extreme multi-label text classification task.",
}

@article{10.1145/3544558,
author = {Bayer, Markus and Kaufhold, Marc-Andr\'{e} and Reuter, Christian},
title = {A Survey on Data Augmentation for Text Classification},
year = {2022},
issue_date = {July 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {55},
number = {7},
issn = {0360-0300},
url = {https://doi.org/10.1145/3544558},
doi = {10.1145/3544558},
abstract = {Data augmentation, the artificial creation of training data for machine learning by transformations, is a widely studied research field across machine learning disciplines. While it is useful for increasing a model's generalization capabilities, it can also address many other challenges and problems, from overcoming a limited amount of training data to regularizing the objective, to limiting the amount of data used to protect privacy. Based on a precise description of the goals and applications of data augmentation and a taxonomy for existing works, this survey is concerned with data augmentation methods for textual classification and aims at providing a concise and comprehensive overview for researchers and practitioners. Derived from the taxonomy, we divide more than 100 methods into 12 different groupings and give state-of-the-art references expounding which methods are highly promising by relating them to each other. Finally, research perspectives that may constitute a building block for future work are provided.},
journal = {ACM Comput. Surv.},
month = {dec},
articleno = {146},
numpages = {39},
keywords = {Data augmentation, low data regimes, small data analytics}
}

@misc{openai2024gpt4technicalreport,
      title={GPT-4 Technical Report}, 
      author={OpenAI and Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko Altenschmidt and Sam Altman and Shyamal Anadkat and Red Avila and Igor Babuschkin and Suchir Balaji and Valerie Balcom and Paul Baltescu and Haiming Bao and Mohammad Bavarian and Jeff Belgum and Irwan Bello and Jake Berdine and Gabriel Bernadett-Shapiro and Christopher Berner and Lenny Bogdonoff and Oleg Boiko and Madelaine Boyd and Anna-Luisa Brakman and Greg Brockman and Tim Brooks and Miles Brundage and Kevin Button and Trevor Cai and Rosie Campbell and Andrew Cann and Brittany Carey and Chelsea Carlson and Rory Carmichael and Brooke Chan and Che Chang and Fotis Chantzis and Derek Chen and Sully Chen and Ruby Chen and Jason Chen and Mark Chen and Ben Chess and Chester Cho and Casey Chu and Hyung Won Chung and Dave Cummings and Jeremiah Currier and Yunxing Dai and Cory Decareaux and Thomas Degry and Noah Deutsch and Damien Deville and Arka Dhar and David Dohan and Steve Dowling and Sheila Dunning and Adrien Ecoffet and Atty Eleti and Tyna Eloundou and David Farhi and Liam Fedus and Niko Felix and Simón Posada Fishman and Juston Forte and Isabella Fulford and Leo Gao and Elie Georges and Christian Gibson and Vik Goel and Tarun Gogineni and Gabriel Goh and Rapha Gontijo-Lopes and Jonathan Gordon and Morgan Grafstein and Scott Gray and Ryan Greene and Joshua Gross and Shixiang Shane Gu and Yufei Guo and Chris Hallacy and Jesse Han and Jeff Harris and Yuchen He and Mike Heaton and Johannes Heidecke and Chris Hesse and Alan Hickey and Wade Hickey and Peter Hoeschele and Brandon Houghton and Kenny Hsu and Shengli Hu and Xin Hu and Joost Huizinga and Shantanu Jain and Shawn Jain and Joanne Jang and Angela Jiang and Roger Jiang and Haozhun Jin and Denny Jin and Shino Jomoto and Billie Jonn and Heewoo Jun and Tomer Kaftan and Łukasz Kaiser and Ali Kamali and Ingmar Kanitscheider and Nitish Shirish Keskar and Tabarak Khan and Logan Kilpatrick and Jong Wook Kim and Christina Kim and Yongjik Kim and Jan Hendrik Kirchner and Jamie Kiros and Matt Knight and Daniel Kokotajlo and Łukasz Kondraciuk and Andrew Kondrich and Aris Konstantinidis and Kyle Kosic and Gretchen Krueger and Vishal Kuo and Michael Lampe and Ikai Lan and Teddy Lee and Jan Leike and Jade Leung and Daniel Levy and Chak Ming Li and Rachel Lim and Molly Lin and Stephanie Lin and Mateusz Litwin and Theresa Lopez and Ryan Lowe and Patricia Lue and Anna Makanju and Kim Malfacini and Sam Manning and Todor Markov and Yaniv Markovski and Bianca Martin and Katie Mayer and Andrew Mayne and Bob McGrew and Scott Mayer McKinney and Christine McLeavey and Paul McMillan and Jake McNeil and David Medina and Aalok Mehta and Jacob Menick and Luke Metz and Andrey Mishchenko and Pamela Mishkin and Vinnie Monaco and Evan Morikawa and Daniel Mossing and Tong Mu and Mira Murati and Oleg Murk and David Mély and Ashvin Nair and Reiichiro Nakano and Rajeev Nayak and Arvind Neelakantan and Richard Ngo and Hyeonwoo Noh and Long Ouyang and Cullen O'Keefe and Jakub Pachocki and Alex Paino and Joe Palermo and Ashley Pantuliano and Giambattista Parascandolo and Joel Parish and Emy Parparita and Alex Passos and Mikhail Pavlov and Andrew Peng and Adam Perelman and Filipe de Avila Belbute Peres and Michael Petrov and Henrique Ponde de Oliveira Pinto and Michael and Pokorny and Michelle Pokrass and Vitchyr H. Pong and Tolly Powell and Alethea Power and Boris Power and Elizabeth Proehl and Raul Puri and Alec Radford and Jack Rae and Aditya Ramesh and Cameron Raymond and Francis Real and Kendra Rimbach and Carl Ross and Bob Rotsted and Henri Roussez and Nick Ryder and Mario Saltarelli and Ted Sanders and Shibani Santurkar and Girish Sastry and Heather Schmidt and David Schnurr and John Schulman and Daniel Selsam and Kyla Sheppard and Toki Sherbakov and Jessica Shieh and Sarah Shoker and Pranav Shyam and Szymon Sidor and Eric Sigler and Maddie Simens and Jordan Sitkin and Katarina Slama and Ian Sohl and Benjamin Sokolowsky and Yang Song and Natalie Staudacher and Felipe Petroski Such and Natalie Summers and Ilya Sutskever and Jie Tang and Nikolas Tezak and Madeleine B. Thompson and Phil Tillet and Amin Tootoonchian and Elizabeth Tseng and Preston Tuggle and Nick Turley and Jerry Tworek and Juan Felipe Cerón Uribe and Andrea Vallone and Arun Vijayvergiya and Chelsea Voss and Carroll Wainwright and Justin Jay Wang and Alvin Wang and Ben Wang and Jonathan Ward and Jason Wei and CJ Weinmann and Akila Welihinda and Peter Welinder and Jiayi Weng and Lilian Weng and Matt Wiethoff and Dave Willner and Clemens Winter and Samuel Wolrich and Hannah Wong and Lauren Workman and Sherwin Wu and Jeff Wu and Michael Wu and Kai Xiao and Tao Xu and Sarah Yoo and Kevin Yu and Qiming Yuan and Wojciech Zaremba and Rowan Zellers and Chong Zhang and Marvin Zhang and Shengjia Zhao and Tianhao Zheng and Juntang Zhuang and William Zhuk and Barret Zoph},
      year={2024},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2303.08774}, 
}

@misc{shakil2024utilizinggptenhancetext,
      title={Utilizing GPT to Enhance Text Summarization: A Strategy to Minimize Hallucinations}, 
      author={Hassan Shakil and Zeydy Ortiz and Grant C. Forbes},
      year={2024},
      eprint={2405.04039},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2405.04039}, 
}

@misc{hendy2023goodgptmodelsmachine,
      title={How Good Are GPT Models at Machine Translation? A Comprehensive Evaluation}, 
      author={Amr Hendy and Mohamed Abdelrehim and Amr Sharaf and Vikas Raunak and Mohamed Gabr and Hitokazu Matsushita and Young Jin Kim and Mohamed Afify and Hany Hassan Awadalla},
      year={2023},
      eprint={2302.09210},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2302.09210}, 
}

@misc{yoo2021gpt3mix,
      title={GPT3Mix: Leveraging Large-scale Language Models for Text Augmentation}, 
      author={Kang Min Yoo and Dongju Park and Jaewook Kang and Sang-Woo Lee and Woomyeong Park},
      year={2021},
      eprint={2104.08826},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{10.1145/3544548.3580688,
author = {H\"{a}m\"{a}l\"{a}inen, Perttu and Tavast, Mikke and Kunnari, Anton},
title = {Evaluating Large Language Models in Generating Synthetic HCI Research Data: a Case Study},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580688},
doi = {10.1145/3544548.3580688},
abstract = {Collecting data is one of the bottlenecks of Human-Computer Interaction (HCI) research. Motivated by this, we explore the potential of large language models (LLMs) in generating synthetic user research data. We use OpenAI’s GPT-3 model to generate open-ended questionnaire responses about experiencing video games as art, a topic not tractable with traditional computational user models. We test whether synthetic responses can be distinguished from real responses, analyze errors of synthetic data, and investigate content similarities between synthetic and real data. We conclude that GPT-3 can, in this context, yield believable accounts of HCI experiences. Given the low cost and high speed of LLM data generation, synthetic data should be useful in ideating and piloting new experiments, although any findings must obviously always be validated with real data. The results also raise concerns: if employed by malicious users of crowdsourcing services, LLMs may make crowdsourcing of self-report data fundamentally unreliable.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {433},
numpages = {19},
keywords = {User models, User experience, Language models, GPT-3},
location = {<conf-loc>, <city>Hamburg</city>, <country>Germany</country>, </conf-loc>},
series = {CHI '23}
}
